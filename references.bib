
@book{mollick_co-intelligence_2024,
	location = {New York, New York},
	title = {Co-intelligence: living and working with {AI}},
	isbn = {978-0-593-71671-7 978-0-593-85250-7},
	shorttitle = {Co-intelligence},
	abstract = {"From Wharton professor and author of the popular One Useful Thing Substack newsletter Ethan Mollick comes the definitive playbook for working, learning, and living in the new age of {AI}. The release of generative {AI}--from {LLMs} like {ChatGPT} to image generators like {DALL}-E-marks a new era. We have invented technologies that boost our physical capabilities and others that automate complex tasks, but never, until now, have we created a technology that can boost our intelligence--with an impact on work and life that researchers project will be greater than that of steam power or the internet. Mollick urges us not to turn away from {AI}, and instead to invite {AI} tools to the table. He demonstrates how {AI} can amplify our own capacities, acting in roles from brainstorming partner to cowriter to tutor to coach, and assesses its surprising, positive impact on business and organizations. Marshalling original research from workers and teams who are leading the rest of us in embracing and leveraging {AI}, Mollick cuts through the hype to make a frank and eye-opening case for the real value of {AI} tools. Moreover, Mollick argues that the long-term impact of {AI} will be different from what we expect, advantaging English majors and art history experts more than coders, and impacting knowledge workers more than blue-collar workers. Co-Intelligence shows what it means for individuals and for society to think together with smart machines, and why it's imperative that we all master that skill. Co-Intelligence challenges us to utilize {AI}'s power without losing our identity, learn from it without being misled, and harness its gifts to create a better human future. Thought-provoking, optimistic, and lucid, Co-Intelligence reveals the promise and power of generative {AI}"--},
	pagetotal = {234},
	publisher = {Portfolio/Penguin},
	author = {Mollick, Ethan},
	date = {2024},
	note = {{OCLC}: on1408648878},
	keywords = {Labor, Social aspects, Education, Artificial intelligence, Expert systems (Computer science), Intelligence artificielle, Systèmes experts (Informatique), Applications en éducation, Aspect social, Éducation, Educational applications, Effect of technological innovations on, Effets des innovations sur, Travail},
}


@misc{word_carpentries_2021,
	title = {The {Carpentries} {Instructor} {Training} {November} 2021},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {carpentries/instructor-training},
	url = {https://zenodo.org/record/5709383},
	abstract = {The Carpentries Instructor Training curriculum - release 18 November 2021.},
	urldate = {2024-07-01},
	publisher = {Zenodo},
	author = {Word, Karen and Sane, Maneesha and Barnes, Kelly and Brown, Sarah M and Michonneau, François and Koch, Christina and Harris, Rayna M and Becker, Erin and Ballsun-Stanton, Brian and Capes, Gerard and Hodges, Toby and Njambi, Serah and Stevens, Sarah and Kamvar, Zhian Namir and Li, Angela and Deardorff, Ariel and Eranti, Pradeep and {SherAaron Hurt} and Nenadic, Aleksandra and Jankowski, Eric and Jordan, Kari L. and Heirendt, Laurent and Cadzow, Murray and Tran, Aaron and Robitaille, Alec L. and Ball, Alexander James and Peterson, Bianca and De Kock, Christa and Chen, Daniel and Vanichkina, Darya P and Pérez-Suárez and McAulay, Elizabeth and Milunovich, George and PROFITI, GIUSEPPE and Gruson, Hugo and Oliver, Jeffrey and Duckles, Jonah and Juvonen, Matti and Förstner, Konrad U. and Nederbragt, Lex and Stokes, Liz and Stoffers, Martin and Black, Michael and Henry, Michael and Davis, Neal and Peter, Sarah and {Sichong} and Liang, Tong and {Ashwin Vishnu Mohanan}},
	month = nov,
	year = {2021},
	doi = {10.5281/ZENODO.5709383},
}

@misc{anthropic_golden_2024,
	title = {Golden {Gate} {Claude}},
	url = {https://www.anthropic.com/news/golden-gate-claude},
	urldate = {2024-07-01},
	author = {{Anthropic}},
	month = may,
	year = {2024},
}

@article{wittgenstein_tractatus_1922,
	title = {Tractatus logico-philosophicus},
	volume = {59},
	journal = {J. Hist. Ideas},
	author = {Wittgenstein, Ludwig},
	year = {1922},
	pages = {1--28},
}

@book{frankfurt_bullshit_2009,
	title = {On {Bullshit}},
	copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	isbn = {978-1-4008-2653-7},
	url = {https://www.degruyter.com/document/doi/10.1515/9781400826537/html},
	abstract = {\#1 New York Times bestseller Featured on The Daily Show and 60 Minutes The acclaimed book that illuminates our world and its politics by revealing why bullshit is more dangerous than lying One of the most prominent features of our world is that there is so much bullshit. Yet we have no clear understanding of what bullshit is, how it’s distinct from lying, what functions it serves, and what it means. In his acclaimed bestseller On Bullshit , Harry Frankfurt, who was one of the world’s most influential moral philosophers, explores this important subject, which has become a central problem of politics and our world. With his characteristic combination of philosophical acuity, psychological insight, and wry humor, Frankfurt argues that bullshitters misrepresent themselves to their audience not as liars do, that is, by deliberately making false claims about what is true. Rather, bullshitters seek to convey a certain impression of themselves without being concerned about whether anything at all is true. They quietly change the rules governing their end of the conversation so that claims about truth and falsity are irrelevant. Although bullshit can take many innocent forms, excessive indulgence in it can eventually undermine the bullshitter’s capacity to tell the truth in a way that lying does not. Liars at least acknowledge that the truth matters. Because of this, bullshit is a greater enemy of the truth than lies are. Remarkably prescient and insightful, On Bullshit is a small book that explains a great deal about our time.},
	language = {en},
	urldate = {2024-07-01},
	publisher = {Princeton University Press},
	author = {Frankfurt, Harry G.},
	month = jan,
	year = {2009},
	doi = {10.1515/9781400826537},
	keywords = {Advertising, Affair, Allusion, Altruism, Anecdote, Ascription, Attention, Bullshit, Carelessness, Cliché, Connotation, Consideration, Criticism, Deception, Deed, Deity, Disgust, Effectiveness, False statement, Falsity, Gibberish, Greatness, Humility, Hyperbole, Indulgence, Instance (computer science), Intention, Lie, Literature, Ludwig Wittgenstein, Max Black, Misrepresentation, Nonsense, Obligation, On Bullshit, Oxford English Dictionary, Oxford University Press, Participant, Personal life, Philosophical analysis, Phrase, Proportion (architecture), Psychological testing, Quackery, Quantity, R., Red tape, Referent, Religion, Shit, Sincerity, Skepticism, Slang, State of affairs (philosophy), State of affairs (sociology), Suggestion, The Other Hand, The Various, Thought, Understanding, Usage, Utterance, Vagueness, Verb, Writing},
}

@incollection{ihde_heideggers_1979,
	address = {Dordrecht},
	title = {Heidegger’s {Philosophy} of {Technology}},
	isbn = {978-94-009-9900-8},
	url = {https://doi.org/10.1007/978-94-009-9900-8_9},
	abstract = {Among the few philosophers to date to have taken technology seriously, it should be apparent that Martin Heidegger is a pioneer in this field. He was among the first to raise technology to a central concern for philosophy and he was among the first to see in it a genuine ontological issue. This is the case in spite of the dominant and sometimes superficial interpretations of Heidegger which see in him only a negative attitude to technology.},
	language = {en},
	urldate = {2024-07-01},
	booktitle = {Technics and {Praxis}},
	publisher = {Springer Netherlands},
	author = {Ihde, Don},
	editor = {Ihde, Don},
	year = {1979},
	doi = {10.1007/978-94-009-9900-8_9},
	pages = {103--129},
}

@misc{mollick_-boarding_2023,
	title = {On-boarding your {AI} {Intern}},
	url = {https://www.oneusefulthing.org/p/on-boarding-your-ai-intern},
	abstract = {There's a somewhat weird alien who wants to work for free for you. You should probably get started.},
	language = {en},
	urldate = {2024-06-30},
	author = {Mollick, Ethan},
	month = may,
	year = {2023},
}

@inproceedings{lewis_retrieval-augmented_2020,
	title = {Retrieval-{Augmented} {Generation} for {Knowledge}-{Intensive} {NLP} {Tasks}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html},
	abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
	urldate = {2024-06-30},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe},
	year = {2020},
	pages = {9459--9474},
}

@book{borges_collected_1998,
	address = {New York, NY},
	series = {Penguin {Classics} {Deluxe} {Edition}},
	title = {Collected fictions},
	isbn = {978-0-14-028680-9 978-0-670-84970-3},
	language = {eng},
	publisher = {Penguin Books},
	author = {Borges, Jorge Luis and Hurley, Andrew},
	year = {1998},
}

@book{pratchett_science_2000,
	address = {London},
	title = {The science of discworld},
	isbn = {978-0-09-187477-3},
	language = {eng},
	publisher = {Ebury},
	author = {Pratchett, Terry and Stewart, Ian and Cohen, Jack},
	year = {2000},
}

@misc{willison_slop_2024,
	title = {Slop is the new name for unwanted {AI}-generated content},
	url = {https://simonwillison.net/2024/May/8/slop/},
	urldate = {2024-06-30},
	author = {Willison, Simon},
	month = may,
	year = {2024},
}

@book{adams_hitchhikers_1995,
	title = {The {Hitchhiker}'s {Guide} to the {Galaxy}},
	isbn = {978-0-345-39180-3},
	url = {https://www.amazon.com/Hitchhikers-Guide-Galaxy-Douglas-Adams/dp/0345391802},
	urldate = {2024-06-30},
	publisher = {Del Ray},
	author = {Adams, Douglas},
	year = {1995},
}

@misc{anthropic_introducing_2024,
	title = {Introducing {Claude} 3.5 {Sonnet}},
	url = {https://www.anthropic.com/news/claude-3-5-sonnet},
	urldate = {2024-06-29},
	author = {{Anthropic}},
	year = {2024},
}

@phdthesis{adkins_historical_1956,
	type = {{PhD} {Thesis}},
	title = {An historical and analytical study of the tally, the knotted cord, the fingers, and the abacus},
	school = {The Ohio State University},
	author = {Adkins, Julia Elizabeth},
	year = {1956},
}

@misc{wills_bug_2022,
	title = {The {Bug} in the {Computer} {Bug} {Story}},
	url = {https://daily.jstor.org/the-bug-in-the-computer-bug-story/},
	abstract = {Soon after a team of engineers discovered a moth in a machine at Harvard, the word "bug" became a standard part of the programmer's lexicon. Or did it?},
	language = {en-US},
	urldate = {2024-06-29},
	journal = {JSTOR Daily},
	author = {Wills, Matthew},
	month = may,
	year = {2022},
}

@article{hicks_chatgpt_2024,
	title = {{ChatGPT} is bullshit},
	volume = {26},
	issn = {1388-1957, 1572-8439},
	url = {https://link.springer.com/10.1007/s10676-024-09775-5},
	doi = {10.1007/s10676-024-09775-5},
	abstract = {Abstract
            
              Recently, there has been considerable interest in large language models: machine learning systems which produce human-like text and dialogue. Applications of these systems have been plagued by persistent inaccuracies in their output; these are often called “AI hallucinations”. We argue that these falsehoods, and the overall activity of large language models, is better understood as
              bullshit
              in the sense explored by Frankfurt (On Bullshit, Princeton, 2005): the models are in an important way indifferent to the truth of their outputs. We distinguish two ways in which the models can be said to be bullshitters, and argue that they clearly meet at least one of these definitions. We further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.},
	language = {en},
	number = {2},
	urldate = {2024-06-28},
	journal = {Ethics and Information Technology},
	author = {Hicks, Michael Townsen and Humphries, James and Slater, Joe},
	month = jun,
	year = {2024},
	pages = {38},
}

@misc{mollick_superhuman_2023,
	title = {Superhuman?},
	url = {https://www.oneusefulthing.org/p/superhuman},
	abstract = {What does it mean for AI to be better than a human? And how can we tell?},
	language = {en},
	urldate = {2024-05-28},
	author = {Mollick, Ethan},
	month = sep,
	year = {2023},
}

@article{ihde_epistemology_2000,
	title = {Epistemology engines},
	volume = {406},
	copyright = {2000 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/35017666},
	doi = {10.1038/35017666},
	abstract = {An antique optical device has powered several centuries of scientific thought.},
	language = {en},
	number = {6791},
	urldate = {2024-01-18},
	journal = {Nature},
	author = {Ihde, Don},
	month = jul,
	year = {2000},
	note = {Number: 6791
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {21--21},
}

@incollection{voloshinov_marxism_1973,
	title = {Marxism and the {Philosophy} of {Language}},
	url = {https://www.marxists.org/archive/voloshinov/1929/marxism-language.htm},
	urldate = {2024-01-19},
	booktitle = {Marxism and the {Philosophy} of {Language}},
	publisher = {Harvard University Press},
	author = {Voloshinov, Valentin},
	year = {1973},
}

@misc{babbage_passages_1864,
	title = {Passages from the {Life} of a {Philosopher}},
	url = {https://www.gutenberg.org/files/57532/57532-h/57532-h.htm},
	urldate = {2024-01-19},
	author = {Babbage, Charles},
	year = {1864},
}

@incollection{haraway_cyborg_2006,
	address = {Dordrecht},
	title = {A {Cyborg} {Manifesto}: {Science}, {Technology}, and {Socialist}-{Feminism} in the {Late} 20th {Century}},
	isbn = {978-1-4020-3803-7},
	shorttitle = {A {Cyborg} {Manifesto}},
	url = {https://doi.org/10.1007/978-1-4020-3803-7_4},
	abstract = {This chapter is an effort to build an ironic political myth faithful to feminism, socialism, and materialism. Perhaps more faithful as blasphemy is faithful, than as reverent worship and identification. Blasphemy has always seemed to require taking things very seriously. I know no better stance to adopt from within the secular-religious, evangelical traditions of United States politics, including the politics of socialist-feminism. Blasphemy protects one from the moral majority within, while still insisting on the need for community. Blasphemy is not apostasy. Irony is about contradictions that do not resolve into larger wholes, even dialectically, about the tension of holding incompatible things together because both or all are necessary and true. Irony is about humor and serious play. It is also a rhetorical strategy and a political method, one I would like to see more honoured within socialist-feminism. At the center of my ironic faith, my blasphemy, is the image of the cyborg.},
	language = {en},
	urldate = {2024-01-19},
	booktitle = {The {International} {Handbook} of {Virtual} {Learning} {Environments}},
	publisher = {Springer Netherlands},
	author = {Haraway, Donna},
	editor = {Weiss, Joel and Nolan, Jason and Hunsinger, Jeremy and Trifonas, Peter},
	year = {2006},
	doi = {10.1007/978-1-4020-3803-7_4},
	keywords = {Advanced Industrial Society, Black Woman, Feminist Standpoint, Late 20th Century, Social Relation},
	pages = {117--158},
}

@misc{dellacqua_navigating_2023,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Navigating the {Jagged} {Technological} {Frontier}: {Field} {Experimental} {Evidence} of the {Effects} of {AI} on {Knowledge} {Worker} {Productivity} and {Quality}},
	shorttitle = {Navigating the {Jagged} {Technological} {Frontier}},
	url = {https://papers.ssrn.com/abstract=4573321},
	doi = {10.2139/ssrn.4573321},
	abstract = {The public release of Large Language Models (LLMs) has sparked tremendous interest in how humans will use Artificial Intelligence (AI) to accomplish a variety of tasks. In our study conducted with Boston Consulting Group, a global management consulting firm, we examine the performance implications of AI on realistic, complex, and knowledge-intensive tasks. The pre-registered experiment involved 758 consultants comprising about 7\% of the individual contributor-level consultants at the company. After establishing a performance baseline on a similar task, subjects were randomly assigned to one of three conditions: no AI access, GPT-4 AI access, or GPT-4 AI access with a prompt engineering overview. We suggest that the capabilities of AI create a “jagged technological frontier” where some tasks are easily done by AI, while others, though seemingly similar in difficulty level, are outside the current capability of AI. For each one of a set of 18 realistic consulting tasks within the frontier of AI capabilities, consultants using AI were significantly more productive (they completed 12.2\% more tasks on average, and completed task  25.1\% more quickly), and produced significantly higher quality results (more than 40\% higher quality compared to a control group). Consultants across the skills distribution benefited significantly from having AI augmentation, with those below the average performance threshold increasing by 43\% and those above increasing by 17\% compared to their own scores. For a task selected to be outside the frontier, however, consultants using AI were 19 percentage points less likely to produce correct solutions compared to those without AI. Further, our analysis shows the emergence of two distinctive patterns of successful AI use by humans along a spectrum of human-AI integration. One set of consultants acted as “Centaurs,” like the mythical halfhorse/half-human creature, dividing and delegating their solution-creation activities to the AI or to themselves. Another set of consultants acted more like “Cyborgs,” completely integrating their task flow with the AI and continually interacting with the technology.},
	language = {en},
	urldate = {2024-01-18},
	author = {Dell'Acqua, Fabrizio and McFowland, Edward and Mollick, Ethan R. and Lifshitz-Assaf, Hila and Kellogg, Katherine and Rajendran, Saran and Krayer, Lisa and Candelon, François and Lakhani, Karim R.},
	month = sep,
	year = {2023},
	keywords = {Edward McFowland, Ethan R. Mollick, Fabrizio Dell'Acqua, François Candelon, Hila Lifshitz-Assaf, Karim R. Lakhani, Katherine Kellogg, Lisa Krayer, Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality, SSRN, Saran Rajendran},
}

@article{ihde_merleau-ponty_2004,
	title = {Merleau-{Ponty} and {Epistemology} {Engines}},
	volume = {27},
	issn = {0163-8548},
	url = {https://www.jstor.org/stable/20010385},
	abstract = {One of us coined the notion of an "epistemology engine." The idea is that some particular technology in its workings and use is seen suggestively as a metaphor for the human subject and often for the production of knowledge itself. In this essay, we further develop the concept and claim that Merleau-Ponty's phenomenological commitments, although suggestive, did not lead him to appreciate the epistemological value of materiality. We also take steps towards establishing how an understanding of this topic can provide the basis for reinterpreting the history of phenomenology.},
	number = {4},
	urldate = {2024-01-18},
	journal = {Human Studies},
	author = {Ihde, Don and Selinger, Evan},
	year = {2004},
	note = {Publisher: Springer},
	pages = {361--376},
}

@misc{bucci_word_2023,
	title = {Word calculators don't add up},
	url = {https://bucci.onl/notes/Word-calculators-dont-add-up},
	urldate = {2024-01-18},
	author = {Bucci, Anthony},
	month = dec,
	year = {2023},
}

@misc{bonger_tu_2023,
	title = {{TU} {Delft} teachers on {ChatGPT}: ‘{Banning} it is pointless'},
	shorttitle = {{TU} {Delft} teachers on {ChatGPT}},
	url = {https://delta.tudelft.nl/en/article/tu-delft-teachers-chatgpt-banning-it-pointless},
	abstract = {Artificial intelligence can help students in their writing and programming assignments. What should TU Delft teachers do about the much talked about ChatGPT? Some opinions.},
	language = {en-GB},
	urldate = {2024-01-17},
	author = {Bonger, Saskia and van der Wal, Rob},
	month = jan,
	year = {2023},
	note = {Section: Education},
}

@misc{willison_think_2023,
	title = {Think of language models like {ChatGPT} as a “calculator for words”},
	url = {https://simonwillison.net/2023/Apr/2/calculator-for-words/},
	abstract = {One of the most pervasive mistakes I see people using with large language model tools like ChatGPT is trying to use them as a search engine. As with other LLM …},
	language = {en-gb},
	urldate = {2024-01-15},
	journal = {Simon Willison's Weblog},
	author = {Willison, Simon},
	month = apr,
	year = {2023},
}

@misc{mollick_opinionated_2023,
	title = {An {Opinionated} {Guide} to {Which} {AI} to {Use}: {ChatGPT} {Anniversary} {Edition}},
	shorttitle = {An {Opinionated} {Guide} to {Which} {AI} to {Use}},
	url = {https://www.oneusefulthing.org/p/an-opinionated-guide-to-which-ai},
	abstract = {A simple answer, and then a less simple one.},
	language = {en},
	urldate = {2024-01-15},
	author = {Mollick, Ethan},
	month = sep,
	year = {2023},
}

@misc{ballsun_stanton_2024_12602858,
  author       = {Ballsun-Stanton, Brian and
                  Hipólito, Inês},
  title        = {{Is the 'Calculator for Words' analogy useful for 
                   communicating about LLMs?}},
  month        = jul,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.12602858},
  url          = {https://doi.org/10.5281/zenodo.12602858}
}